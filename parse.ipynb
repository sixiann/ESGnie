

import pandas as pd
import math
from collections import Counter
from nltk import corpus
import string
import boto3
from wordcloud import WordCloud
from matplotlib import pyplot as plt
import re
import numpy as np
import io

#%%

AWS_S3_BUCKET = 'esgnie'

def get_s3_companies(s3_client, bucket='esgnie', comp_prefix='companies/'):
    ## get companies
    result = s3_client.list_objects(Bucket=bucket, Prefix=comp_prefix, Delimiter='/')
    l_subdir = [com_prefix.get('Prefix').replace(comp_prefix, '').replace('/', '')
                for com_prefix in result.get('CommonPrefixes')]
    return l_subdir

def get_company_files(s3_client, ticker, bucket='esgnie', filename_pattern=None, comp_prefix='companies'):
    result = s3_client.list_objects(Bucket=bucket, Prefix=f"{comp_prefix}/{ticker}/")
    df_files = pd.DataFrame()
    df_files['file'] = [obj['Key'] for obj in result['Contents']]
    df_files['filename'] = [file.split('/')[-1] for file in df_files['file']]
    if filename_pattern is not None:
        df_files['pattern_match'] = [1 if re.match(filename_pattern, file) else 0 for file in df_files['filename']]
    # df_files[df_files['pattern_match'] == 1]['filename'].tolist()
    return df_files[df_files['pattern_match'] == 1]['file'].tolist()

def write_csv_to_s3(s3_client, df, file, bucket='esgnie'):
    with io.StringIO() as csv_buffer:
        df.to_csv(csv_buffer, index=False)
        response = s3_client.put_object(
            Bucket=bucket, Key=file, Body=csv_buffer.getvalue()
        )
        status = response.get("ResponseMetadata", {}).get("HTTPStatusCode")
    return status

#%%


def quants_parser(df):
    df.drop(['Unnamed: 0', 'filename', 
                  'quants_ratio_page', 'level_3', 'xbar','ybar', 
                  'upright', 'direction','digits_ratio', 'years_ratio',
                  'dates_ratio',
                 'keyword_flag','keyword_col_flag','keyword_row_flag'], axis=1)
    
    #Add a column determining height of text
    df["text_height"] = df.bottom-df.top

    #Add a column determining whether text is numeric 
    is_numeric = []
    for text in list(df.text):  
        t="".join(c for c in text if c.isalnum())
        is_numeric.append(t.isnumeric())

    df["numeric_flag"] = is_numeric
    
    #masks
    quantmask1 = df["quant_row_flag"] == 1
    quantmask2 = df["quants_ratio_page"] > 0.1
    yearmask1 = df["year_flag"] == 1
    
    if len(df.text_height.mode()) == 1:
        heightmask = df["text_height"] > float(df.text_height.mode())
    else: 
        heightmask = df["text_height"] > float(df.text_height.min())
        
    textmask = df["numeric_flag"] == 0
    
    #header rows
    header_rows = df[heightmask & ~quantmask1 & textmask]
    
    #item/variable name
    items = df[quantmask1 & ~yearmask1 & ~heightmask & textmask & quantmask2]
    
    #non quantitative rows
    nonquant_rows = pd.concat([items, df]).drop_duplicates(keep=False)
    
    #quantitative rows
    mask1 = items["text"] != "Indicator"
    mask2 = items["text"] != "Items"

    quant_rows = items[mask1 & mask2].row_num.unique()
    quantmask2 = df["row_num"].isin(quant_rows)

    quant_rows = df[quantmask2 & ~textmask]

    rows_of_df = []
    columns_of_df = ["ticker", "Page Number", "Variable", "Date", "Value"]


    def f(qr):

        leftmask = df.x0  >= math.floor(qr.x0) -25 
        rightmask = df.x1 <= math.ceil(qr.x1) + 25
        rowmask2 = df.row_num <= qr.row_num
        quantmask2 = df.row_num.isin(quant_rows)
        
        company = df.company.iloc[0]
        pagenum = df.pagenum.iloc[0]
        
        if items[items.row_num == qr.row_num].empty:
            variable = " "
        else:
            variable = items[items.row_num == qr.row_num].iloc[0].text
        
        if df[~quantmask2 & leftmask & rightmask & rowmask2 & yearmask1].empty:
            date = " "
        else:
            date = df[~quantmask2 & leftmask & rightmask & rowmask2 & yearmask1].iloc[0].text
        
        value = qr.text

        row = [company, pagenum, variable, date, value]
        rows_of_df.append(row)
        return rows_of_df

    quant_rows.apply(f,axis = 1)

    df2 = pd.DataFrame(rows_of_df, columns = columns_of_df)
    
    return header_rows, nonquant_rows, items, df2


#%%


def textfinder(items):
    L = list(items.text)
    words = ' '.join(L).lower()
    words = words.translate(words.maketrans('', '', string.digits))
    
    L = words.split(" ")

    dic = Counter(L)
    sortedtext = {k: v for k, v in sorted(dic.items(), key=lambda item: item[1], reverse = True)}
    
    df = pd.DataFrame.from_dict({"word": sortedtext.keys(), "freq": sortedtext.values()})
    return words, df


#%%


custom = ["", "must", "co.", "ltd.", "()", "')", "co.,", "(cid:)", ",,.", ",,,.", 
          "year", "rmb", "december", "total", "company","china", "group", 
          "others", "two", "within", "one", "item", "million", "billion", 
          "sinopec", "–", "—", ",,", "(,)"]
stopwords = corpus.stopwords.words('english')
stopwords = stopwords + list(string.punctuation) + list(string.digits) + custom

def commonwords(final):
    words, df = textfinder(final)
    sw = df.word.isin(stopwords)
    
    wordcloud = WordCloud(stopwords=stopwords, background_color="white", 
                          height = 300, max_words = 100).generate(words)
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.show()
    
    return df[~sw]



#%%

s3_client = boto3.client('s3')
l_ticker = get_s3_companies(s3_client)
ticker = l_ticker[0]
l_files = get_company_files(s3_client, ticker=ticker, filename_pattern='^df_cells')


finalDF = pd.DataFrame()
finalITEMS = pd.DataFrame()
finalNONQUANT = pd.DataFrame()

for file in l_files:
    obj = s3_client.get_object(Bucket='esgnie', Key=file)
    df = pd.read_csv(obj['Body'])
    header_rows, nonquant_rows, items, df2 = quants_parser(df)
    finalDF = finalDF.append(df2)
    finalITEMS = finalITEMS.append(items)
    finalNONQUANT = finalNONQUANT.append(nonquant_rows)

# for df in [finalDF, finalITEMS, finalNONQUANT]:
#     status = write_csv_to_s3(s3_client, df, "word_freq/overall.csv", bucket='esgnie')
    
#      ## check upload status
#      if status == 200:
#          print(f"Successful S3 put_object response. Status - {status}")
#      else:
#          print(f"Unsuccessful S3 put_object response. Status - {status}")


#%%

items = commonwords(finalITEMS)
nonquant = commonwords(finalNONQUANT)

#%%
overall = items.rename(columns={"freq": "freq_quant_row"})

#%%
freq_nonquant_row = []

for word in items.word:
    if word in list(nonquant.word):
        freq_nonquant_row.append(int(nonquant[nonquant.word == word].freq))
    else:
        freq_nonquant_row.append(0)

# #%%

# overall["freq_nonquant_row"] = freq_nonquant_row
# overall["freq_diff"] = np.array(overall.freq_quant_row) - np.array(freq_nonquant_row)
# overall.sort_values(by=['freq_diff'], ascending = False)

# #%%

# status = write_csv_to_s3(s3_client, overall, "word_freq/overall.csv", bucket='esgnie')

# ## check upload status
# if status == 200:
#     print(f"Successful S3 put_object response. Status - {status}")
# else:
#     print(f"Unsuccessful S3 put_object response. Status - {status}")
    
    
# #%%

# status = write_csv_to_s3(s3_client, items, "word_freq/quant_rows.csv", bucket='esgnie')

# ## check upload status
# if status == 200:
#     print(f"Successful S3 put_object response. Status - {status}")
# else:
#     print(f"Unsuccessful S3 put_object response. Status - {status}")
    
# #%%

# status = write_csv_to_s3(s3_client, nonquant, "word_freq/nonquant_rows.csv", bucket='esgnie')

# ## check upload status
# if status == 200:
#     print(f"Successful S3 put_object response. Status - {status}")
# else:
#     print(f"Unsuccessful S3 put_object response. Status - {status}")
